{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cap 1 - Pinhole Camera Model\n",
    "\n",
    "A pinhole camera is a Linear Camera with or without lens and with a single small aperture. Light rays pass through the aperture and project an inverted image on the opposite side of the camera. Think of the virtual image plane as being in front of the camera and containing the upright image of the scene.\n",
    "\n",
    "<img src=\"imgs/simplemodel.png\" style=\"background : white\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A point $P$ in the 3-D world can be obtained by an image sensor according to the following image, using the virtual image plane as image plane.\n",
    "\n",
    "<img src=\"imgs/pinhole_camera_model.png\" style=\"background : white\">\n",
    "\n",
    "Where:\n",
    "\n",
    "- $[X_w \\ Y_w \\ Z_w]$ is the point coordinates in the world reference system. \n",
    "- $[X_c \\ Y_c \\ Z_c]$ is the point coordinates in the camera reference system.\n",
    "- $[x \\ y]$ is the point coordinates in sensor plane in [mm].\n",
    "- $[u \\ v]$ is the point coordinates in image plane in [pixels].  It's our primary source of information of the world. We will use this to lead us to, at least, $[X_c \\ Y_c \\ Z_c]$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From 3-D to 2-D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation from World to Camera Coordinate Frame\n",
    "\n",
    "The transformation from the <u>world coordinate</u> frame to the <u>camera coordinate</u> frame is a 3D to 3D transformation. This is achieved using the extrinsic parameters of the camera, which are the rotation matrix (R) and the translation vector (T). The rotation matrix represents the orientation of the camera, while the translation vector represents its position in the world coordinate frame. It is given by:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "X_c \\\\\\\n",
    "Y_c \\\\\\\n",
    "Z_c\n",
    "\\end{bmatrix} = R_{3\\times 3}\n",
    "\\begin{bmatrix}\n",
    "X_w \\\\\\\n",
    "Y_w \\\\\\\n",
    "Z_w\n",
    "\\end{bmatrix} +\n",
    "\\begin{bmatrix}\n",
    "t_x \\\\\\\n",
    "t_y \\\\\\\n",
    "t_z\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Which in homegeneus matrix is given by:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "X_c \\\\\n",
    "Y_c \\\\\n",
    "Z_c \\\\\n",
    "1\n",
    "\\end{bmatrix} = \n",
    "\\underbrace{\n",
    "    \\begin{bmatrix}\n",
    "        R_{3 \\times 3} & t_{3\\times 1} \\\\\n",
    "        0_{1\\times 3} & 1 \n",
    "    \\end{bmatrix}\n",
    "}_{Extrinsinc \\ parameters \\ T_{4\\times 4}}\n",
    "\\begin{bmatrix}\n",
    "X_w \\\\\n",
    "Y_w \\\\\n",
    "Z_w \\\\\n",
    "1\n",
    "\\end{bmatrix}   \\ \\ \\ (1)\n",
    "$$\n",
    "\n",
    "### Transformation from camera coordinate frame to sensor plane\n",
    "\n",
    "By similarity of triangles we can make the perspective projection between the <u>Camera reference</u> system and the <u>Image Plane</u>:\n",
    "\n",
    "$$\n",
    "\\frac{x}{X_C}=\\frac{f}{Z_c} \\rightarrow x = \\frac{X_cf}{Z_c} \\\\\n",
    "\\frac{y}{Y_C}=\\frac{f}{Z_c} \\rightarrow y = \\frac{Y_cf}{Z_c} \n",
    "$$\n",
    "\n",
    "### Transformation from sensor plane to image plane\n",
    "\n",
    "$$\n",
    "u = f_x\\frac{X_c}{Z_c} + c_x\\\\\n",
    "v = f_y\\frac{Y_c}{Z_c} + c_y\\\\\n",
    "$$\n",
    "\n",
    "Where $f_x = fm_x$ and $f_y = fm_y$. $m_x$ and $m_y$ pixel densities in $x$ and $y$ directions.\n",
    "\n",
    "Which in homegeneus matrix is given by:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    u \\\\\\\n",
    "    v \\\\\\\n",
    "    1\n",
    "\\end{bmatrix} \\equiv Z_c\n",
    "\\begin{bmatrix}\n",
    "    u \\\\\\\n",
    "    v \\\\\\\n",
    "    1\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "    f_xX_c + c_xZ_c \\\\\\\n",
    "    f_yY_c + c_yZ_c \\\\\\\n",
    "    1\n",
    "\\end{bmatrix} =\n",
    "\\underbrace{\n",
    "    \\begin{bmatrix}\n",
    "        f_x & 0 & c_x & 0 \\\\\\\n",
    "        0 & f_y & c_y & 0 \\\\\\\n",
    "        0 & 0 & 1 & 0\n",
    "    \\end{bmatrix}\n",
    "}_{Intrinsic \\ parameters \\ [K_{3\\times 3}|0]}\n",
    "\\begin{bmatrix}\n",
    "    X_c \\\\\\\n",
    "    Y_c \\\\\\\n",
    "    Z_c \\\\\\\n",
    "    1\n",
    "\\end{bmatrix}   \\ \\ \\ (2)\n",
    "$$\n",
    "\n",
    "The coordinate of a point in the world on the image plane can be achieved by combining equations (1) and (2):\n",
    "\n",
    "$$Z_c\n",
    "\\begin{bmatrix}\n",
    "u \\\\\n",
    "v \\\\\n",
    "1\n",
    "\\end{bmatrix}=\n",
    "\\underbrace{\n",
    "        \\underbrace{\n",
    "            \\begin{bmatrix}\n",
    "                f_x & 0 & c_x & 0 \\\\\n",
    "                0 & f_y & c_y & 0 \\\\\n",
    "                0 & 0 & 1 & 0\n",
    "            \\end{bmatrix}\n",
    "        }_{Intrinsic \\ parameters \\ [K_{3\\times 3}|0]}\n",
    "        \\underbrace{\n",
    "            \\begin{bmatrix}\n",
    "                R_{3 \\times 3} & t_{3\\times 1} \\\\\n",
    "                0_{1 \\times 3} & 1 \n",
    "            \\end{bmatrix}\n",
    "        }_{Extrinsic \\ parameters \\ T_{4\\times 4}}\n",
    "}_{P_{3\\times 4}}\n",
    "\\begin{bmatrix}\n",
    "X_w \\\\\n",
    "Y_w \\\\\n",
    "Z_w \\\\\n",
    "1\n",
    "\\end{bmatrix}  \\ \\ \\ (3)\n",
    "$$\n",
    "\n",
    "The matrix $P_{3\\times 4}$ is the <u>projection matrix</u> or in older computer vision contexts <u>camera matrix</u>. The intrinsic parameters $(f_x,f_y,c_x,c_y)$ sets up the intrinsic matrix $K$ and can be <u>informed by manufacturer</u> or found after the [calibration process from 3-D pattern](<Theory 1.2-CameraCalibration3DPattern.ipynb>) and are assumed to be known. The matrix $T$ is so called <u>extrinsic matrix</u> or <u>camera pose</u> in homogeneus form.\n",
    "\n",
    "We can also perform good $K$ and $R$ estimation after the [calibration process from 2-D pattern](<Theory 1.1-CameraCalibration2DPattern.ipynb>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important notes:\n",
    "\n",
    "- Scaling the projection matrix $P$, implies simultaneously scaling the world and the camera, which does not change the image.\n",
    "- $kP$ and $P$ produces the same $\\begin{bmatrix}    u \\\\\\    v \\\\\\    1\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1 ) Given the camera matrix $C = \\begin{bmatrix} 512 & -800 & 0 & 800 \\\\\\ 512 & 0 & -8000 & 1600 \\\\\\ 1 & 0 & 0 & 0\\end{bmatrix}$, compute the image plane coodinate in the world at [4, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera pose ($T$) after displacement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use equation (1) to transform a point expressed in the world frame into the camera frame before any displacement:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "X_c \\\\\n",
    "Y_c \\\\\n",
    "Z_c \\\\\n",
    "1\n",
    "\\end{bmatrix} = \n",
    "_{c_1}{\\left[T\\right]}_{w}\n",
    "\\begin{bmatrix}\n",
    "X_w \\\\\n",
    "Y_w \\\\\n",
    "Z_w \\\\\n",
    "1\n",
    "\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "- $_{c_1}{\\left[T\\right]}_{w}$ is the camera pose for position 1, before any displacement, also called camera 1.\n",
    "- $_{c_2}{\\left[T\\right]}_{w}$ is the camera pose for position 2, after some displacement, also called camera 2.\n",
    "- $_{c_3}{\\left[T\\right]}_{w}$ is the camera pose for position 3, after more displacement, also called camera 3.\n",
    "\n",
    "To transform a 3D point expressed in the camera 2 frame to the camera 1 frame:\n",
    "\n",
    "$$\n",
    "_{c_1}{\\left[T\\right]}_{c_2} = _{c_1}{\\left[T\\right]}_{w} \\cdot _{w}{\\left[T\\right]}_{c_2} = \n",
    "_{c_1}{\\left[T\\right]}_{w} \\cdot {(_{c_2}{\\left[T\\right]}_{w})}^{-1} = \n",
    "\\begin{bmatrix}\n",
    "_{c_1}{\\left[R\\right]}_{w}  & _{c_1}{\\left[t\\right]}_{w}  \\\\\n",
    "0_{1 \\times 3} & 1\n",
    "\\end{bmatrix}  \\cdot\n",
    "\\begin{bmatrix}\n",
    "{(_{c_2}{\\left[R\\right]}_{w})}^T  & - {(_{c_2}{\\left[R\\right]}_{w})}^T \\cdot  _{c_2}{\\left[t\\right]}_{w} \\\\\n",
    "0_{1 \\times 3} & 1\n",
    "\\end{bmatrix} =\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "_{c_1}{\\left[R\\right]}_{w} \\cdot {(_{c_2}{\\left[R\\right]}_{w})}^T  & - _{c_1}{\\left[R\\right]}_{w} \\cdot {(_{c_2}{\\left[R\\right]}_{w})}^T \\cdot  _{c_2}{\\left[t\\right]}_{w} + _{c_1}{\\left[t\\right]}_{w} \\\\\n",
    "0_{1 \\times 3} & 1\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "_{c_1}{\\left[R\\right]}_{c_2}  & _{c_1}{\\left[t\\right]}_{c_2}  \\\\\n",
    "0_{1 \\times 3} & 1\n",
    "\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "Assim:\n",
    "\n",
    "$$\n",
    "_{c_1}{\\left[R\\right]}_{c_2} = _{c_1}{\\left[R\\right]}_{w} \\cdot {(_{c_2}{\\left[R\\right]}_{w})}^T  \n",
    "$$\n",
    "$$\n",
    "_{c_1}{\\left[t\\right]}_{c_2} = - \\underbrace{_{c_1}{\\left[R\\right]}_{w} \\cdot {(_{c_2}{\\left[R\\right]}_{w})}^T}_{_{c_1}{\\left[R\\right]}_{c_2}} \\cdot  _{c_2}{\\left[t\\right]}_{w} + _{c_1}{\\left[t\\right]}_{w}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2 ) Given the camera pose at positions 1 and 2: \n",
    "\n",
    "$$T_1 = \\begin{bmatrix} 1 & 0 & 0 & 10 \\\\\\ 0 & 1 & 0 & 20 \\\\\\ 0 & 0 & 1 & 30 \\\\\\ 0 & 0 & 0 & 1\\end{bmatrix}$$\n",
    "$$T_2 = \\begin{bmatrix} -1 & 0 & 0 & 10 \\\\\\ 0 & -1 & 0 & 10 \\\\\\ 0 & 0 & 1 & 10 \\\\\\ 0 & 0 & 0 & 1\\end{bmatrix}$$\n",
    "\n",
    "Compute the displacement between thesse positions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image plane point (712.0, 912.0)\n",
      "Image plane point (712.0, 912.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "C = np.array([[512, -800, 0,    800],\n",
    "              [512, 0,    -800, 1600],\n",
    "              [1,   0,    0,    0]])\n",
    "Pw = np.array([4,0,0]) # Point in world reference\n",
    "\n",
    "# Solution\n",
    "def warp(C, Pw):\n",
    "    Pw_homogeneus = np.hstack( (Pw, [1]) )  # array([4, 0, 0, 1])\n",
    "    Pi_homogeneus = C @ Pw_homogeneus # Point in image reference = array([2848, 3648,    4])\n",
    "    Pi_homogeneus = Pi_homogeneus/Pi_homogeneus[2] # array([712., 912.,   1.])\n",
    "    u , v = Pi_homogeneus[0], Pi_homogeneus[1] # (712.0, 912.0)\n",
    "    return u, v\n",
    "\n",
    "print(f\"Image plane point {warp(C, Pw)}\")\n",
    "# Try scale C to find the same answer\n",
    "C = 4*C\n",
    "print(f\"Image plane point {warp(C, Pw)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera displacement:\n",
      " Rotation:\n",
      "[[-1.  0.  0.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0.  1.]]\n",
      " translation:\n",
      " [ 20.  30. -20.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "Tworld_to_1 = np.array([[1, 0, 0, 10],\n",
    "                        [0, 1, 0, 20],\n",
    "                        [0, 0, 1, 30],\n",
    "                        [0, 0, 0, 1]])\n",
    "Tworld_to_2 = np.array([[ -1, 0 , 0, 10],\n",
    "                        [ 0 , -1, 0, 10],\n",
    "                        [ 0 , 0 , 1, 10],\n",
    "                        [ 0 , 0 , 0, 1]])\n",
    "\n",
    "# Solution\n",
    "def displacement(Tworld_to_1,Tworld_to_2):\n",
    "    T1_to_world = np.linalg.inv(Tworld_to_1)\n",
    "    T1_to_2 = Tworld_to_2 @ T1_to_world\n",
    "    R1_to_2 = T1_to_2[0:3,0:3]\n",
    "    t1_to_2 = T1_to_2[0:3,3]\n",
    "    return R1_to_2, t1_to_2\n",
    "R, t = displacement(Tworld_to_1,Tworld_to_2)\n",
    "print(f\"Camera displacement:\\n Rotation:\\n{R}\\n translation:\\n {t}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
